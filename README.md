# ğŸš€ Backend Engineer Hiring Assignment

## ğŸ“‹ Objective
This project implements a **Lead Qualification & Scoring Backend Service**.

The goal is to:
- Build **clean and well-documented backend APIs**
- Integrate an **AI Model (Gemini)** for reasoning
- Use **rule-based logic** + **AI reasoning** to score leads
- Deliver a **working, testable backend** with deployment, Docker, and CI/CD

---

## ğŸ§© Features Implemented

âœ… Offer & Lead Upload APIs  
âœ… CSV Upload & Parsing  
âœ… Rule-Based + AI-Based Scoring Pipeline  
âœ… OpenRouter API Integration  
âœ… Result Storage in Supabase DB  
âœ… CSV Export Endpoint  
âœ… Swagger API Documentation  
âœ… Unit Tests for Rule Layer  
âœ… Dockerized Application  
âœ… CI/CD Pipeline (GitHub Actions)  
âœ… AWS Deployment  

---

## ğŸ§  Tech Stack

| Category | Technology |
|-----------|-------------|
| **Backend Framework** | Node.js + Express |
| **AI Integration** | Google Gemini API |
| **Database** | Supabase (PostgreSQL) |
| **File Handling** | Multer + CSV Parser |
| **Testing** | Jest |
| **Containerization** | Docker |
| **Deployment** | AWS |
| **CI/CD** | GitHub Actions |
| **Docs** | Swagger |

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
2ï¸âƒ£ Install Dependencies
bash
Copy code
npm install
3ï¸âƒ£ Configure Environment Variables
Create a .env file in the project root:

env
Copy code
PORT=3001

# --- Supabase Database ---
DB_HOST=aws-1-ap-south-1.pooler.supabase.com
DB_PORT=6543
DB_USERNAME=postgres.lfwnlbdxawasnkxyiubk
DB_PASSWORD=Sharma@1234
DB_DATABASE=postgres
DB_SYNCHORNIZATION=true

SUPABASE_URL=https://lfwnlbdxawasnkxyiubk.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...


# --- Optional ---
OPENROUTER_API_KEY=sk-or-v1-*********************
4ï¸âƒ£ Run the Server
bash
Copy code
npm run start:dev
Your app will start on:
ğŸ‘‰ http://localhost:3000

ğŸ“˜ API Documentation (Swagger)
Once your server is running, access the complete API documentation at:

ğŸ‘‰ Swagger UI:

bash
Copy code
http://localhost:3000/api-docs
Swagger provides:

Interactive API testing

Request/response schema details

Example payloads for each endpoint

ğŸ§  API Endpoints Overview
ğŸŸ© POST /offer
Accepts offer/product information.

Example Request:
json
Copy code
{
  "name": "AI Outreach Automation",
  "value_props": ["24/7 outreach", "6x more meetings"],
  "ideal_use_cases": ["B2B SaaS mid-market"]
}
ğŸŸ¦ POST /leads/upload
Uploads a CSV file with lead data.

CSV Columns:

pgsql
Copy code
name,role,company,industry,location,linkedin_bio
Example cURL:
bash
Copy code
curl -X POST http://localhost:3000/leads/upload \
  -F "file=@leads.csv"
ğŸŸ¨ POST /score
Runs the scoring pipeline (Rule + AI).

Rule Layer (50 Points Max)
Factor	Condition	Points
Role Relevance	Decision Maker	+20
Influencer	+10
Industry Match	Exact ICP	+20
Adjacent	+10
Data Completeness	All fields present	+10

AI Layer (50 Points Max)
Uses Gemini model to classify High / Medium / Low intent

Maps as:

High â†’ +50

Medium â†’ +30

Low â†’ +10

Final Score = Rule Score + AI Score

ğŸŸ§ GET /results
Returns all scored leads.

Example Response:
json
Copy code
[
  {
    "name": "Ava Patel",
    "role": "Head of Growth",
    "company": "FlowMetrics",
    "intent": "High",
    "score": 85,
    "reasoning": "Fits ICP SaaS mid-market and role is decision maker."
  }
]
ğŸŸª GET /results/export
Exports the final results as a downloadable CSV file.

ğŸ§  Example Prompt for Gemini
text
Copy code
You are a lead qualification AI. 
Given the product offer and the lead details, classify the lead's intent as High, Medium, or Low. 
Explain your reasoning in 1â€“2 sentences.

Offer: "AI Outreach Automation" - 24/7 outreach, 6x more meetings
Lead: "Head of Growth at FlowMetrics, SaaS industry"
ğŸ§ª Testing
Run Unit Tests:
bash
Copy code
npm run test
Covers:

Rule-based logic

CSV parsing

Endpoint validation

ğŸ³ Docker Setup
Build Docker Image
bash
Copy code
docker build -t lead-scoring-backend .
Run Container
bash
Copy code
docker run -p 3001:3001 --env-file .env lead-scoring-backend
App runs on:
ğŸ‘‰ http://localhost:3000

âš™ï¸ CI/CD Pipeline
Configured with GitHub Actions to:

Run tests on every push

Build Docker image

Deploy automatically to AWS

â˜ï¸ Deployment
Deployed on AWS EC2 / Elastic Beanstalk
Live API Base URL (example):

arduino
Copy code
https://leadscore-api.example.com
ğŸ§¾ Database (Supabase)
All lead and offer data is stored and visualized through Supabase
for a clear and user-friendly database dashboard.

ğŸ“¸ Supabase Dashboard Screenshot:

(Place your screenshot in /assets/supabase-dashboard.png before pushing to GitHub)

ğŸ§© Folder Structure
bash
Copy code
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/          # env & app config
â”‚   â”œâ”€â”€ controllers/     # API route handlers
â”‚   â”œâ”€â”€ services/        # business logic + AI integration
â”‚   â”œâ”€â”€ utils/           # helpers, parsers, validators
â”‚   â”œâ”€â”€ tests/           # Jest test cases
â”‚   â””â”€â”€ app.js
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â””â”€â”€ .env
ğŸ“¦ Submission Summary
Feature	Status
Offer & Lead APIs	âœ… Done
Scoring Pipeline	âœ… Done
Gemini Integration	âœ… Done
Supabase Integration	âœ… Done
CSV Export	âœ… Done
Swagger Docs	âœ… Done
Tests	âœ… Done
Docker	âœ… Done
CI/CD	âœ… Done
AWS Deployment	âœ… Done

ğŸ’¡ Author
Priyanshu Sharma
Backend Developer | Node.js | NestJS | AI Integration
ğŸ“§ priyanshusharma784@gmail.com
ğŸŒ GitHub: https://github.com/Priyanshusharma07/kuvaka_tech
Leetcode : https://leetcode.com/u/Sharma00015/

